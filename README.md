# üìû Telecom Churn Prediction System

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0+-orange.svg)](https://scikit-learn.org/)
[![Pandas](https://img.shields.io/badge/Pandas-1.3+-green.svg)](https://pandas.pydata.org/)
[![Status](https://img.shields.io/badge/Status-Complete-success.svg)]()

Sistema de Machine Learning para predicci√≥n temprana de cancelaci√≥n de clientes en empresas de telecomunicaciones, utilizando t√©cnicas de ensamble y optimizaci√≥n de hiperpar√°metros.

---

## üìã Tabla de Contenidos

- [Descripci√≥n del Proyecto](#-descripci√≥n-del-proyecto)
- [Problema de Negocio](#-problema-de-negocio)
- [Dataset](#-dataset)
- [Metodolog√≠a](#-metodolog√≠a)
- [Pipeline de Procesamiento](#-pipeline-de-procesamiento)
- [Modelos Implementados](#-modelos-implementados)
- [Resultados](#-resultados)
- [Hallazgos Clave](#-hallazgos-clave)
- [Instalaci√≥n y Uso](#-instalaci√≥n-y-uso)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Tecnolog√≠as](#-tecnolog√≠as)
- [Conclusiones](#-conclusiones)
- [Contacto](#-contacto)

---

## Descripci√≥n del Proyecto

Este proyecto desarrolla un **modelo de ensamble** que permite predecir tempranamente si un cliente cancelar√° el servicio de telecomunicaciones (churn), adem√°s de identificar las caracter√≠sticas que m√°s inciden en la separaci√≥n de clientes. El objetivo es proporcionar a la empresa herramientas para implementar **estrategias de retenci√≥n proactivas** y reducir la tasa de abandono.

---

## Problema de Negocio

La **cancelaci√≥n de clientes** (churn) representa uno de los principales desaf√≠os para las empresas de telecomunicaciones, impactando directamente en:

- **Ingresos recurrentes**: P√©rdida de clientes activos y reducci√≥n del ARPU (Average Revenue Per User)
- **Costos de adquisici√≥n**: Adquirir un nuevo cliente cuesta 5-7 veces m√°s que retener uno existente
- **Brand reputation**: Alta tasa de churn se√±aliza problemas de satisfacci√≥n del cliente

**Objetivo del modelo**: Identificar clientes con alto riesgo de abandono **antes** de que cancelen, permitiendo intervenciones personalizadas y cost-effective.

---

## Dataset

### Caracter√≠sticas del Dataset

- **Registros**: 3,333 clientes
- **Variables**: 11 atributos (10 predictores + 1 objetivo)
- **Distribuci√≥n de clases**: 
  - Clase 0 (No Churn): 2,850 clientes (85.5%)
  - Clase 1 (Churn): 483 clientes (14.5%)
- **Valores nulos**: 0 (dataset limpio)

### Diccionario de Datos

| Variable | Tipo | Descripci√≥n |
|----------|------|-------------|
| **Churn** | int | **Variable objetivo**: 1 si el cliente cancel√≥, 0 si no |
| AccountWeeks | int | N√∫mero de semanas con cuenta activa |
| ContractRenewal | int | 1 si renov√≥ contrato recientemente, 0 si no |
| DataPlan | int | 1 si tiene plan de datos, 0 si no |
| DataUsage | float | GB de uso mensual de datos |
| CustServCalls | int | N√∫mero de llamadas al servicio al cliente |
| DayMins | float | Promedio de minutos diurnos al mes |
| DayCalls | int | N√∫mero medio de llamadas diurnas |
| MonthlyCharge | float | Factura mensual media ($) |
| OverageFee | float | Mayor cuota de exceso en √∫ltimos 12 meses ($) |
| RoamMins | float | Minutos de roaming |

---

## Metodolog√≠a

El proyecto sigue el framework **CRISP-DM** (Cross-Industry Standard Process for Data Mining):

### 1. **Business Understanding**
   - Definici√≥n del problema de churn
   - Identificaci√≥n de m√©tricas de √©xito (Recall, Precision, F1-Score)
   - Establecimiento de objetivos: maximizar detecci√≥n de clientes en riesgo

### 2. **Data Understanding**
   - An√°lisis exploratorio de datos (EDA)
   - Visualizaci√≥n de distribuciones
   - An√°lisis de correlaciones
   - Detecci√≥n de outliers mediante boxplots

### 3. **Data Preparation**
   - Verificaci√≥n de tipos de datos
   - Divisi√≥n train/test (80/20)
   - Escalado de caracter√≠sticas (StandardScaler para SVM y Regresi√≥n Log√≠stica)
   - Balanceo de clases con SMOTE (Synthetic Minority Over-sampling Technique)

### 4. **Modeling**
   - Implementaci√≥n de m√∫ltiples algoritmos
   - Optimizaci√≥n de hiperpar√°metros con GridSearchCV
   - Validaci√≥n cruzada (5-fold CV)
   - T√©cnicas de ensamble (Bagging, Random Forest)

### 5. **Evaluation**
   - Comparaci√≥n de modelos mediante m√©tricas de clasificaci√≥n
   - An√°lisis de feature importance
   - Identificaci√≥n de clientes de alto riesgo

### 6. **Deployment**
   - Generaci√≥n de predicciones probabil√≠sticas
   - Ranking de clientes por probabilidad de churn
   - Recomendaciones para intervenci√≥n

---

## Pipeline de Procesamiento

```python
# 1. Carga de datos
df = pd.read_csv('telecom_churn.csv')

# 2. Divisi√≥n de datos
X = df.drop(columns=['Churn'])
y = df['Churn']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)

# 3. Balanceo con SMOTE (solo para Bagging)
sm = SMOTE(random_state=42)
X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)

# 4. Escalado (solo para SVM y Regresi√≥n Log√≠stica)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 5. Entrenamiento del modelo
best_model = RandomForestClassifier(
    n_estimators=190,
    max_features='sqrt',
    oob_score=True
)
best_model.fit(X_train, y_train)

# 6. Predicci√≥n y evaluaci√≥n
y_pred = best_model.predict(X_test)
y_prob = best_model.predict_proba(X_test)[:, 1]
```

---

## Modelos Implementados

### 1. **Decision Tree (Baseline)**
   - Modelo inicial sin optimizaci√≥n
   - **Problema detectado**: Overfitting severo (100% accuracy en train)
   - **Resultados Test**: Accuracy 87.9%, Recall 64.2%

### 2. **Decision Tree + GridSearchCV**
   - Optimizaci√≥n de hiperpar√°metros: `max_depth`, `min_samples_leaf`
   - Mejores par√°metros: `max_depth=10`, `min_samples_leaf=0.01`
   - **Resultados Test**: Accuracy 92.4%, Precision 87.9%, Recall 53.7%
   - **Mejora**: Elimina overfitting, aumenta precisi√≥n

### 3. **Bagging Classifier + SMOTE**
   - 200 estimadores (√°rboles de decisi√≥n)
   - Balanceo de clases con SMOTE
   - **Resultados Test**: Accuracy 90.0%, Precision 61.5%, Recall 79.0%
   - **Trade-off**: Mayor recall a costa de menor precisi√≥n

### 4. **Bagging Heterog√©neo**
   - Combinaci√≥n de: Decision Tree, SVM (RBF), SVM (Sigmoid), Regresi√≥n Log√≠stica
   - **Resultados Test**: Accuracy 87.0%, Recall 16.0%
   - **Conclusi√≥n**: No supera al Bagging homog√©neo (Decision Trees puros)

### 5. **Random Forest** ‚≠ê
   - 45 estimadores, `class_weight='balanced'`
   - **Resultados Test**: Accuracy 93.2%, Precision 83.8%, Recall 65.3%
   - **Ventajas**: Balance √≥ptimo entre m√©tricas

### 6. **Random Forest + GridSearchCV** üèÜ **MEJOR MODELO**
   - B√∫squeda exhaustiva de hiperpar√°metros
   - Mejores par√°metros: `n_estimators=190`, `max_features='sqrt'`
   - **Resultados Test**: 
     - **Accuracy**: 93.7%
     - **Precision**: 83.5%
     - **Recall**: 69.5%
     - **F1-Score**: 75.9%
     - **ROC AUC**: 89.5%

---

## Resultados

### Comparativa de Modelos (Test Set)

| Modelo | Accuracy | Precision | Recall | F1-Score | ROC AUC |
|--------|----------|-----------|--------|----------|---------|
| Decision Tree (Baseline) | 87.9% | 56.5% | 64.2% | 60.1% | 78.0% |
| Decision Tree + GridSearch | 92.4% | 87.9% | 53.7% | 66.7% | 89.8% |
| Bagging + SMOTE | 90.0% | 61.5% | 79.0% | 69.1% | 90.2% |
| Bagging Heterog√©neo | 87.0% | 62.0% | 16.0% | 25.0% | - |
| Random Forest | 93.2% | 83.8% | 65.3% | 73.4% | 89.9% |
| **Random Forest + GridSearch** | **93.7%** | **83.5%** | **69.5%** | **75.9%** | **89.5%** |

### Interpretaci√≥n de M√©tricas (Modelo Final)

- **Accuracy 93.7%**: El modelo clasifica correctamente 93.7% de todos los clientes
- **Precision 83.5%**: De los clientes que el modelo predice que abandonar√°n, 83.5% realmente lo hacen (bajo falsos positivos)
- **Recall 69.5%**: El modelo detecta 69.5% de todos los clientes que realmente abandonan
- **F1-Score 75.9%**: Balance harm√≥nico entre Precision y Recall
- **ROC AUC 89.5%**: Excelente capacidad discriminatoria entre clases

### Matriz de Confusi√≥n (Random Forest + GridSearch)

```
                 Predicho: No Churn    Predicho: Churn
Real: No Churn         560                 12
Real: Churn             29                 66
```

- **True Negatives (TN)**: 560 - Clientes fieles correctamente identificados
- **False Positives (FP)**: 12 - Clientes fieles err√≥neamente marcados como riesgo
- **False Negatives (FN)**: 29 - Clientes en riesgo **no detectados** (30.5% de los churns)
- **True Positives (TP)**: 66 - Clientes en riesgo correctamente identificados

---

## Hallazgos Clave

### 1. **Feature Importance (Random Forest + GridSearch)**

Las 4 variables m√°s influyentes en la predicci√≥n de churn:

| Variable | Importancia | Insight de Negocio |
|----------|-------------|--------------------|
| **DayMins** | ~0.30 | Alto uso de minutos diurnos indica engagement, bajo uso se√±aliza riesgo |
| **CustServCalls** | ~0.23 | M√∫ltiples llamadas a servicio al cliente correlacionan fuertemente con churn |
| **MonthlyCharge** | ~0.12 | Facturas elevadas sin valor percibido aumentan probabilidad de cancelaci√≥n |
| **ContractRenewal** | ~0.09 | Falta de renovaci√≥n reciente es se√±al temprana de desengagement |

**Recomendaciones**:
- Monitorear clientes con **3+ llamadas al servicio al cliente** ‚Üí Intervenci√≥n proactiva
- Segmentar clientes con **bajo uso de minutos** (<143.7 min/mes) ‚Üí Ofertas de retenci√≥n
- Revisar percepci√≥n de valor en clientes con **MonthlyCharge > $66** ‚Üí Programas de fidelizaci√≥n

### 2. **Trade-offs entre Modelos**

- **Decision Tree + GridSearch**: 
  - ‚úÖ Alta precisi√≥n (87.9%) ‚Üí Pocos falsos positivos
  - ‚ùå Bajo recall (53.7%) ‚Üí Pierde muchos clientes en riesgo
  
- **Bagging + SMOTE**: 
  - ‚úÖ Alto recall (79.0%) ‚Üí Detecta m√°s churns
  - ‚ùå Baja precisi√≥n (61.5%) ‚Üí Genera muchos falsos positivos (desperdicio de recursos en retenci√≥n)
  
- **Random Forest + GridSearch** (seleccionado): 
  - ‚úÖ Balance √≥ptimo (Precision 83.5%, Recall 69.5%)
  - ‚úÖ Mejor ROC AUC (89.5%)
  - **Justificaci√≥n**: Maximiza valor de negocio minimizando costos de campa√±a (baja FP) y p√©rdida de clientes (aceptable FN)

---

## Tecnolog√≠as

### Lenguaje
- **Python 3.8+**

### Librer√≠as de Data Science
- **Pandas 1.3+**: Manipulaci√≥n y an√°lisis de datos
- **NumPy 1.21+**: Operaciones num√©ricas
- **Matplotlib 3.4+**: Visualizaci√≥n est√°tica
- **Seaborn 0.11+**: Visualizaci√≥n estad√≠stica avanzada

### Machine Learning
- **Scikit-learn 1.0+**: 
  - Modelos: `DecisionTreeClassifier`, `RandomForestClassifier`, `BaggingClassifier`, `SVC`, `LogisticRegression`
  - Preprocessing: `StandardScaler`, `train_test_split`
  - Optimizaci√≥n: `GridSearchCV`, `RandomizedSearchCV`
  - M√©tricas: `accuracy_score`, `precision_score`, `recall_score`, `f1_score`, `roc_auc_score`, `confusion_matrix`
- **Imbalanced-learn 0.8+**: `SMOTE` (balanceo de clases)
- **Statsmodels 0.13+**: An√°lisis estad√≠stico

### Entorno
- **Jupyter Notebook**: Desarrollo interactivo
- **Git**: Control de versiones

---

## Conclusiones

### Fortalezas del Modelo

**Alta precisi√≥n general (93.7%)**: El modelo identifica correctamente la mayor√≠a de los clientes

**Excelente precisi√≥n en clase positiva (83.5%)**: De los clientes marcados como riesgo, 83.5% realmente lo son ‚Üí Bajo desperdicio de recursos en campa√±as de retenci√≥n

**Recall aceptable (69.5%)**: Detecta 7 de cada 10 clientes que abandonar√°n ‚Üí Permite intervenciones preventivas efectivas

**Feature importance interpretable**: Las variables m√°s importantes (`DayMins`, `CustServCalls`) tienen sentido de negocio claro y son accionables

**ROC AUC alto (89.5%)**: Excelente capacidad discriminatoria entre clientes fieles y en riesgo

### Limitaciones

**Recall no perfecto (69.5%)**: El modelo no detecta ~30% de los churns reales ‚Üí Algunos clientes en riesgo no reciben intervenci√≥n

**Desbalance de clases**: Solo 14.5% de la muestra es churn ‚Üí El modelo podr√≠a estar sesgado hacia la clase mayoritaria

**Datos est√°ticos**: El dataset no captura comportamiento temporal ni tendencias ‚Üí El modelo no puede predecir cambios bruscos en engagement

**Variables limitadas**: No incluye informaci√≥n sobre:
   - Historial de pagos / morosidad
   - Satisfacci√≥n del cliente (NPS)
   - Competencia / ofertas externas
   - Interacciones digitales (app, web)

### Trabajo Futuro

**Mejoras T√©cnicas**:
- Implementar **modelos de boosting** (XGBoost, LightGBM, CatBoost) para mejorar recall
- Explorar **redes neuronales** para capturar relaciones no lineales complejas
- Aplicar **t√©cnicas de ensemble stacking** combinando m√∫ltiples modelos
- Incorporar **validaci√≥n temporal** (time-based split) si se obtienen datos hist√≥ricos

**Mejoras de Datos**:
- Agregar **variables de comportamiento temporal** (tendencias de uso, decaimiento de engagement)
- Incluir **datos de interacciones omnichannel** (email, chat, app)
- Incorporar **variables de satisfacci√≥n** (NPS, CSAT scores)
- Enriquecer con **datos externos** (ofertas de competidores, condiciones econ√≥micas)

**Despliegue en Producci√≥n**:
- Desarrollar **API REST** para integraci√≥n con CRM
- Implementar **re-entrenamiento autom√°tico** con nuevos datos
- Crear **dashboard interactivo** para visualizaci√≥n de riesgo de churn por segmento
- Establecer **sistema de alertas** para clientes de alto riesgo

---

## Contacto

**Gast√≥n Gonz√°lez Ovalle**  
Data Scientist | Bioingenier√≠a + Machine Learning

- Email: [ggobuchupureo@gmail.com](mailto:ggobuchupureo@gmail.com)
- LinkedIn: [linkedin.com/in/gaston-gonzalez-ovalle](https://www.linkedin.com/in/gaston-gonzalez-ovalle/)
- GitHub: [github.com/ggobuchupureo](https://github.com/ggobuchupureo)

---
